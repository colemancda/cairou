#!/usr/bin/env python3

import sys
import os
import lxml.html
import urllib.request
import docopt


DOCOPT = """{0}

Usage:
  {0} [options]

Options:
  -h --help     Show this help message.
  --url=URL     Use the specified URL as input source.
  --file=FILE   Use the local FILE as input source.

This utility converts the specified HTML input source (either from a URL or
from a file saved to disk) to an ANSI-C header. If neither --url or --input
are specified, this utility will http://glyphicons.com as a default.

This utility is used with the Cairou library.

https://github.com/cubicool/cairou
""".format(os.path.basename(sys.argv[0]))


HEADER = """\
#ifndef CAIROU_GLYPHICONS_H
#define CAIROU_GLYPHICONS_H

/* Generated by glyphicons-conv. */

#define CAIROU_NUM_ICONS {num}
#define CAIROU_LARGEST_ICON_NAME {largest}

extern const char* _cairou_icon_strings[CAIROU_NUM_ICONS];
extern const char* _cairou_icon_names[CAIROU_NUM_ICONS];

typedef enum _cairou_icon_t {{
{enums},
\tCAIROU_ICON_ERROR
}} cairou_icon_t;

#endif

"""

SOURCE = """\
/* Generated by glyphicons-conv. */

#include "cairou-glyphicons.h"

const char* _cairou_icon_strings[CAIROU_NUM_ICONS] = {{
{strs}
}};

const char* _cairou_icon_names[CAIROU_NUM_ICONS] = {{
{names}
}};
"""


PYTHON = """\
# Generated by glyphicons-conv.

{enums}
"""


# Fetches the data from the specified URL while masquerading as
# Mozilla/5.0 User-Agent. This is necessary for the glyphicons.com
# website, it seems.
def get_url(url):
    return urllib.request.urlopen(urllib.request.Request(
        url,
        headers={"User-Agent": "Mozilla/5.0"}
    ))


def format_enum(s):
    return "\tCAIROU_ICON_%s" % s.upper().replace("-", "_")


def format_str(s):
    utf = chr(int(s, 16)).encode("utf8")

    return "\t\"%s\"" % "".join("\\x%x" % b for b in utf)


def format_name(s):
    return "\t\"%s\"" % s.lower().replace("-", "_")


def format_pyenum(i, s):
    return "ICON_%s = %d" % (s.upper().replace("-", "_"), i)


if __name__ == "__main__":
    args = docopt.docopt(DOCOPT, version="glyphicons-conv 0.1")
    input_url = args["--url"]
    input_file = args["--file"]

    if input_url:
        input_src = get_url(input_url)

    elif input_file:
        input_src = open(os.path.abspath(os.path.expanduser(input_file)))

    else:
        input_src = get_url("http://glyphicons.com")

    data = lxml.html.parse(input_src)
    divs = data.xpath("//div[@data-prefix='glyphicons']")
    largest = max(len(d.values()[2]) for d in divs)

    with open("cairou-glyphicons.h", "w") as output:
        enums = ",\n".join(format_enum(div.values()[2]) for div in divs)

        output.write(HEADER.format(
            enums=enums,
            num=len(divs),
            largest=largest
        ))

    with open("cairou-glyphicons.c", "w") as output:
        strs = ",\n".join(format_str(div.values()[3]) for div in divs)
        names = ",\n".join(format_name(div.values()[2]) for div in divs)

        output.write(SOURCE.format(strs=strs, num=len(divs), names=names))

    with open("glyphicons.py", "w") as output:
        enums = "\n".join(
            format_pyenum(i, div.values()[2]) for i, div in enumerate(divs)
        )

        output.write(PYTHON.format(enums=enums))
